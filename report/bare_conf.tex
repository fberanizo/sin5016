\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{url}
\usepackage[utf8]{inputenc}

\hyphenation{}

\begin{document}
\title{Relatório do Trabalho 1\\ de Aprendizado de Máquina}

\author{\IEEEauthorblockN{Fábio Beranizo Fontes Lopes}
\IEEEauthorblockA{Escola de Artes, Ciências e Humanidades (EACH)\\
Universidade de São Paulo (USP)\\
Email: f.lopes@usp.br}}

\maketitle

Este relatório tem como objetivo mostrar os procedimentos e resultados do Trabalho 1 da disciplina de Aprendizado de Máquina. O propósito dessa tarefa foi testar diferentes algoritmos em atividades de reconhecimento biométrico. Duas técnicas de aprendizado supervisionado foram escolhidas para comparação: Multilayer Perceptron (MLP) e Support Vector Machines (SVM).
% Ambos algoritmos foram implementados em Python.

As seções a seguir explicam as atividades de pré-processamento do conjunto de dados, o treinamento dos modelos e uma discussão dos resultados obtidos.

\section{Base de Dados}
A base de dados utilizada neste trabalho foi a Homologous Multi-modal Traits Database da Shandong University (SDUMLA-HMT) \cite{sdumlahtm}. Este conjunto de dados contém faces de 106 indivíduos em 7 diferentes ângulos. Estas imagens foram capturadas com diferentes poses, expressões faciais, acessórios e iluminações, assemelhando-se a uma aplicação real. 

Cada amostra deste conjunto é rotulada com o indivíduo que aparece na foto, tornando possível aplicar técnicas de aprendizado supervisionado para classificação.

\subsection{Pré-processamento}
Originalmente, as imagens do SDUMLA-HTML possuem resolução 480x640 e estão no formato RGB. Antes de realizar a extração de características das imagens, a região de interesse foi segmentada aplicando-se o Algoritmo Viola-Jones. Em uma segunda etapa, as imagens foram convertidas para escala de cinza a sua dimensão alterada para 128x128.

\subsection{Transformada Wavelet}
A extração de caracterísicas das imagens utilizou a transformada Wavelet. Esta técnica de processamento de sinal realiza a análise de um dado sinal no domínio do tempo e frequência \cite{costa2011ensemble}. Uma função Wavelet pode ser descrita como uma função que apresenta média zero e obedece a Equação:

\[\int_{-\infty}^{\infty} \Psi(t)dt = 0\]

Para utilizar a transformada Wavelet em imagens 2D as linhas e colunas são tratadas como sinais independentes. Ao final da decomposição Wavelet 2D são geradas 4 subimagens. Três delas (HL, LH, HH) contém os detalhes horizontais, verticais e diagonais da imagem original. Uma outra (LL) é uma aproximação da imagem original.

Ao final deste processo são gerados coeficientes que podem ser utilizados para representar a imagem original. Os coeficentes da imagem LL são geralmente os mais utilizados, pois apresentam menor dimensão e boa representatividade \cite{burrus1997introduction}.

\section{Classificadores}
Duas técnicas de aprendizado supervisionado foram implementadas para este trabalho: MLP e SVM. Estas técnicas não serão descritas em detalhe, pois já foram apresentadas em aula.

\subsection{MLP}
Multilayer Perceptron é um tipo de rede neural artificial feedforward. Neste trabalho, o treinamento das redes foi realizado utilizando a estratégia de backpropagation. O método do gradiente conjugado (de Polak-Ribière) foi o escolhido para otimizar os modelos, com a taxa de aprendizado definida pelo método de bisseção. Na seção \ref{sec:discussao} será mostrado que a utilização deste método permitiu acelerar a convergência dos treinamentos quando comparado à taxa de aprendizado fixa.

O critério de parada do treinamento da MLP foi dado pelo erro de validação. Esta estratégia reserva algumas amostras não utilizadas em treino, e computa o erro de validação destes dados a cada época. Quando o valor do erro de validação não diminuir por 5 épocas\footnote{Valor arbitrário, baseado em empirismo} seguidas, o treinamento é interrompido. Trata-se de uma estratégia para minimizar overfitting (pouca capacidade de generalização dos modelos).

MLPs são sensíveis à alta-dimensionalidade dos dados. Portanto, antes do treinamento foi necessário aplicar uma Análise de Componentes Principais (PCA) aos coeficientes obtidos da transformada Wavelet. Este procedimento selecionou um número de componentes de forma que a variância dos dados fosse pelo menos 90\%$^1$ do valor original. O resultado final definiu aproximadamente 70 valores para utilização no treinamento, variando de acordo da função wavelet, sub-bandas e nível de decomposição.

Uma das vantagens da MLP é o fato de lidar naturalmente com problemas multiclasses. Neste trabalho, dada uma imagem era necessário definir a qual dos 106 indivíduos ela pertence. Na rede neural isso se reflete com a existência de 106 neurônios na camada de saída, em que a ativação de cada um representa a identificação de um indivíduo.

%TODO: Inserir imagem mostrando erro de treino e validação
%TODO: Falar do ajuste de parâmetros: número de neurônio na camada oculta

\subsection{SVM}
Máquinas de Vetores Suporte são classificadores que efetuam a separação de amostras em um espaço, geralmente fazendo uso de uma função Kernel para realizar projeção de dados não linearmente separáveis no espaço original. Neste trabalho foi implementado o algoritmo Sequential Minimal Optimization (SMO), conforme visto em aula. 

Diferentemente da MLP, SVMs são insensíveis à alta-dimensionalidade e não necessitam do uso de PCA. Por outro lado, este algorítmo apresenta o problema de ser originalmente para classificação binária. Isto fez necessário o uso de estratégia de classificação multi-classe, neste caso: One-vs-all. Neste método, foi necessário treinar um classificador para cada um dos 106 indivíduos, classificando-os em +1 (é o indivíduo) e -1 (não é o indivíduo). O critério de decisão foi dado pela maior distância da amostra ao hiperplano de separação.

Três tipos de função de kernel foram implementados para este trabalho: linear, gaussiano de base radial (rbf) e polinomial. Os parâmetros C, gamma e degree (grau do polinômio) foram ajustados durante o treinamento por meio de uma busca em grid.

\subsection{Ensembles}
Ver a tese do aluno do clodoaldo.

\section{Avaliação}
A avaliação do 

\section{Resultados}

\section{Discussão} \label{sec:discussao}

\section{Conclusão}


%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}

%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}

\bibliographystyle{IEEEtran}
\bibliography{bare_conf}

\end{document}